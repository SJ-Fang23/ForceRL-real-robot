
# FLEX-real-robot - UR5
This contains instructions on how to run the FLEX code on the UR5 arm to open a drawer.


## How to Power Up the Robot

1. Push the power button on the `teaching pendant` (the tablet).
2. From the warning sign, select `Run to initialization option`.
3. Push `ON` to power up the robotic arm.
4. Press `START` to release the brakes.
5. Push `OK` in the bottom right.

## How to Bring Up the Drivers on the Computer
On the computer connected to the UR5 arm, follow these steps:

1. Open a terminal and run the following commands:
    ```bash
    cd ~/catkin_ws
    source devel/setup.bash
    export ROS_IP=10.3.4.100
    ```

2. Launch the bringup launch file:
    ```bash
    roslaunch turbo_bringup right_arm.launch
    ```
    You will see the gripper opening and closing, indicating a successful launch!

## Teaching Pendant Setup

1. On the main screen, click `Run Program`.
2. Go to `File --> Load Program`.
3. Select `ur_driver.urp` and click `Open`.
4. Press `Play` (`â–¶` symbol).

Voila! We are done!

## How to Launch the Camera Drivers

On the same computer connected to the UR5, follow these steps:

1. Open a terminal and run the following commands:
    ```bash
    cd ~/catkin_ws/src/ForceRL_driver_bk/launch
    roslaunch realsense.launch
    ```

Now you have successfully launched all the drivers for the UR5 arm and sensors.

## Running FLEX

To run FLEX, follow these steps on the computer connected to the UR5 arm:


1. Open a terminal and run:
    ```bash
    rosrun forcerl_driver grasp_object_driver.py
    ```
    If you see something like "Ready to take commands for planning group...", you're good to go!

Now switch to the computer that can run the models for FLEX.

### On the Computer Running FLEX Models

1. In a terminal, run:
    ```bash
    source devel/setup.bash
    ```

2. Set up `ROS_IP` and `ROS_MASTER_URI` to use the `roscore` of the client machine:
    ```bash
    export ROS_IP=10.3.13.148
    export ROS_MASTER_URI=http://10.3.4.100:11311
    ```

> **Note:** Do this step for every terminal you open!

3. Run the point transform to convert camera frame proposals to world frame using the `tf2` package of ROS:
    ```bash
    rosrun frl_rollout point_transform.py
    ```

4. On another terminal, run:
    ```bash
    rosrun frl_rollout send_action.py
    ```
    This will send the commands to be executed on the arm. Keep pressing `Enter` on both computers to successfully execute the actions.

## Running the Policy for Opening the Drawer

1. In a new terminal, activate the conda environment:
    ```bash
    conda activate frl
    ```

2. Run the policy:
    ```bash
    python src/frl_rollout/scripts/policy_server.py
    ```

> **Note:** Make sure you're in the directory `~/projects/frl-real/ForceRL-real-robot` to run the above code.

3. On another terminal, deactivate conda:
    ```bash
    conda deactivate
    ```

4. Source the environment:
    ```bash
    source devel/setup.bash
    ```

5. Don't forget to export `ROS_IP` and `ROS_MASTER_URI`:
    ```bash
    export ROS_IP=10.3.13.148
    export ROS_MASTER_URI=http://10.3.4.100:11311
    ```

6. Run the rollout policy:
    ```bash
    rosrun frl_rollout rollout_policy.py
    ```

This will send the commands to be executed on the arm. Keep pressing `Enter` on both computers to successfully execute the actions.


OH MY GOD!! We can now demonstrate FLEX to Si!


Later!!



# Code structure

## pointcloud_seg
This package is for getting the segmented depth image to the target object given a segmentation mask. The segmented depth image is useful for generating segmeted point cloud for grasp proposals.



## depth_image.py
This is a simple script for converting masked depth image generated by ```pointcloud_seg``` into pointcloud.

## frl_rollout
This is the "server" side for the real robot code. It runs the policy and send action command to the client machine which is connected with the robot.

# Running the code
The grasp proposals for drawer are stored in ```real_small_drawer.npz```
## When already having the grasp proposals

1. The usual stuff
```
souce devel/setup.bash
```

2. setup ROS_IP and ROS_MASTER_URI to use the roscore of the cilent machine
```
export ROS_IP=10.3.13.148
export ROS_MASTER_URI=http://10.3.4.100:11311
```

3. Launch the cilent and robot driver codes on the cilent machine

4. run the point_transform to transform the camera frame proposals to world frame using ```tf2``` package of ROS. 
```
rosrun frl_rollout point_transform.py
```

5. 



